{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lithology classification\n",
    "\n",
    "## Data\n",
    "\n",
    "This notebook uses data from the [Upper Condamine Catchment](http://www.bom.gov.au/qld/flood/brochures/condamine_balonne/map_upper.shtml) in the state of Queensland. The data is sourced from personal communication as a project output. It may be shared publicly and downloadable from this sample notebook in the future.\n",
    "\n",
    "![Upper Condamine catchment formations](img/Upper_Condamine_formations.png \"Upper Condamine catchment formations\")\n",
    "\n",
    "(Figure from [this paper](https://www.researchgate.net/figure/Upper-Condamine-catchment-Queensland-Australia-The-Marburg-Subgroup-consists-of_fig1_283184727))\n",
    "\n",
    "## Status\n",
    "\n",
    "As of May 2019 this present document is an output from exploratory work done during an internship by [Sudhir Gupta](https://github.com/Sudhir22).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This notebook compares the performance of two techniques for semi-automated classification . It also summarise work using ontologies for classification for cases where we do not have reliable training sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:54:38.357642Z",
     "start_time": "2018-02-27T01:54:36.460827Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only True for co-dev of ela from this use case:\n",
    "ela_from_source = False\n",
    "ela_from_source = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ela_from_source:\n",
    "    if ('ELA_SRC' in os.environ):\n",
    "        root_src_dir = os.environ['ELA_SRC']\n",
    "    elif sys.platform == 'win32':\n",
    "        root_src_dir = r'C:\\Users\\SUD011\\Documents\\pyela-sudhir'\n",
    "    else:\n",
    "        username = os.environ['USER']\n",
    "        root_src_dir = os.path.join('/home', username, 'src/github_jm/pyela')\n",
    "    pkg_src_dir = root_src_dir\n",
    "    sys.path.append(pkg_src_dir)\n",
    "\n",
    "from ela.textproc import *\n",
    "from ela.utils import *\n",
    "from ela.classification import *\n",
    "from ela.visual import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import striplog\n",
    "from striplog import Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('ELA_DATA' in os.environ):\n",
    "    data_path = os.environ['ELA_DATA']\n",
    "elif sys.platform == 'win32':\n",
    "    data_path = r'C:\\data\\Lithology'\n",
    "else:\n",
    "    username = os.environ['USER']\n",
    "    data_path = os.path.join('/home', username, 'data', 'Lithology')\n",
    "\n",
    "condamine_litho_dir = os.path.join(data_path,'Condamine')\n",
    "condamine_litho_xl = os.path.join(condamine_litho_dir, 'MASTER_CONDAMINE_Interpretation_all_combined_Jan2017.xlsx')\n",
    "condamine_litho_pkl = os.path.join(condamine_litho_dir, 'MASTER_CONDAMINE_Interpretation_all_combined_Jan2017.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the lithology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(condamine_litho_pkl):\n",
    "    train_data=pd.read_excel(condamine_litho_xl)\n",
    "    with open(condamine_litho_pkl, 'wb') as handle:\n",
    "        pickle.dump(train_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(condamine_litho_pkl, 'rb') as handle:\n",
    "        train_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_unprocessed = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LITHO_CLASS_COL = 'Simplified_lithology'\n",
    "set(train_data[LITHO_CLASS_COL].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LITHO_CLASS_STRATA_COL = 'Simplified_lithology_stratigraphy'\n",
    "set(train_data[LITHO_CLASS_STRATA_COL].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We massage the column of simplified lithologies, resulting from a manual classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[LITHO_CLASS_COL] = train_data[LITHO_CLASS_COL].replace(np.nan,'',regex=True)\n",
    "train_data[LITHO_CLASS_COL] = train_data[LITHO_CLASS_COL].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_data[LITHO_CLASS_COL].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq(train_data[LITHO_CLASS_COL].values, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[LITHO_CLASS_COL] = train_data[LITHO_CLASS_COL].replace('granite|granodiorite|diorite|basement','bedrock',regex=True)\n",
    "train_data[LITHO_CLASS_COL] = train_data[LITHO_CLASS_COL].replace('gravel','alluvium',regex=False)\n",
    "train_data[LITHO_CLASS_COL] = train_data[LITHO_CLASS_COL].replace('wrong_location|weathering_horizon|tertiary','unknown',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq(train_data[LITHO_CLASS_COL].values, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_data\n",
    "LITHO_DESC_COL='Lithology_original'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = df[LITHO_DESC_COL]\n",
    "descs = descs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not obvious from inspection of the the pandas  data frame, but there appears to be NaNs that cause headaches later on.\n",
    "vv = [x for x in df[LITHO_DESC_COL].values if not type(x) is str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = [type(x) is not str for x in df[LITHO_DESC_COL].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[np.array(vv)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs[LITHO_DESC_COL] = descs[LITHO_DESC_COL].replace(np.nan,'',regex=True)\n",
    "descs[LITHO_DESC_COL] = descs[LITHO_DESC_COL].str.lower()\n",
    "\n",
    "descs = descs[LITHO_DESC_COL]\n",
    "descs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = Lexicon.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "expanded_descs = descs.apply(lex.expand_abbreviations)\n",
    "y = expanded_descs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = v_lower(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "flat = flat_list_tokens(y)\n",
    "len(set(flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_common= token_freq(flat, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq(df_most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining lithology classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithologies = ['alluvium', 'basalt', 'bedrock', 'clay', 'sandstone','sand','shale','soil','honeycomb','gravel','coal','gravel','silt','soil','rock', 'limestone']\n",
    "\n",
    "any_litho_markers_re = r'alluvium|sand|clay|ston|shale|basa|silt|soil|honey|coal|gravel|rock|mud'\n",
    "regex = re.compile(any_litho_markers_re)\n",
    "\n",
    "lithologies_dict = dict([(x,x) for x in lithologies])\n",
    "lithologies_dict['sands'] = 'sand'\n",
    "lithologies_dict['clays'] = 'clay'\n",
    "lithologies_dict['shales'] = 'shale'\n",
    "lithologies_dict['claystone'] = 'clay'\n",
    "lithologies_dict['siltstone'] = 'silt'\n",
    "lithologies_dict['mudstone'] = 'silt' # ??\n",
    "lithologies_dict['capstone'] = 'limestone' # ??\n",
    "lithologies_dict['ironstone'] = 'sandstone' # ??\n",
    "lithologies_dict['topsoil'] = 'soil' # ??\n",
    "\n",
    "lithologies_adjective_dict = {\n",
    "    'sandy' :  'sand',\n",
    "    'clayey' :  'clay',\n",
    "    'clayish' :  'clay',\n",
    "    'shaley' :  'shale',\n",
    "    'silty' :  'silt',\n",
    "    'gravelly' :  'gravel'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tokens = v_word_tokenize(t)\n",
    "vt = v_find_litho_markers(v_tokens, regex=regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mark = len([x for x in vt if len(x) == 0 ])\n",
    "at_least_one_mark = len([x for x in vt if len(x) >= 1])\n",
    "at_least_two_mark = len([x for x in vt if len(x) >= 2])\n",
    "print('There are %s entries with no marker, %s entries with at least one, %s with at least two'%(zero_mark,at_least_one_mark,at_least_two_mark))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the regular expression model on the Condamine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_litho = [find_primary_lithology(x, lithologies_dict) for x in vt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(set(prim_litho))\n",
    "plot_freq(token_freq(prim_litho, n_most_common = n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_map={\n",
    "    'alluvium' :  'alluvium',\n",
    "    'bedrock' :  'bedrock',\n",
    "    'basalt' :  'basalt',\n",
    "    'honeycomb' :  'basalt',\n",
    "    'clay' :  'bedrock',\n",
    "    'coal' :  'bedrock', \n",
    "    'sandstone' :  'bedrock',\n",
    "    'sand' :  'alluvium',\n",
    "    '' :  'unknown',\n",
    "    'soil' :  'alluvium',\n",
    "    'shale': 'bedrock',\n",
    "    'gravel': 'alluvium',\n",
    "    'silt' : 'bedrock',\n",
    "    'rock' : 'bedrock',\n",
    "    'limestone' : 'alluvium'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prim_litho=list()\n",
    "for x in prim_litho:\n",
    "    final_prim_litho.append(lithology_map[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq(final_prim_litho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_lithology=train_data[LITHO_CLASS_COL].tolist()\n",
    "\n",
    "def get_accuracy(final_prim_litho, actual):\n",
    "    count=0\n",
    "    for i in range(0,len(final_prim_litho)):\n",
    "        if final_prim_litho[i].lower()==actual[i].lower():\n",
    "            count=count+1\n",
    "    return count/len(final_prim_litho)\n",
    "\n",
    "print(\"Accuracy of regex for classifying primary lithologies: \", get_accuracy(final_prim_litho, simplified_lithology))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "REGEX_LITHO_CLASS_COL='Regex_lithoclass'\n",
    "\n",
    "blah = pd.DataFrame({ LITHO_CLASS_COL: train_data[LITHO_CLASS_COL], REGEX_LITHO_CLASS_COL: final_prim_litho, LITHO_DESC_COL: descs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_check_lithoclass(blah, 'unknown', colname=REGEX_LITHO_CLASS_COL, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud,STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wordcloud(text, title = None, max_words=200, max_font_size=40, seed=1, scale=3, figsize=(12, 12)):\n",
    "    \"\"\"Plot wordclouds from text\n",
    "\n",
    "        Args:\n",
    "            text (str or list of str): text to depict\n",
    "    \"\"\"\n",
    "    if text is list:\n",
    "        text = ' '.join(text)\n",
    "    stopwords = set(STOPWORDS)\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=max_words,\n",
    "        max_font_size=max_font_size, \n",
    "        scale=scale,\n",
    "        random_state=seed\n",
    "    ).generate(text)\n",
    "    fig = plt.figure(1, figsize=figsize)\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = blah.loc[ blah[REGEX_LITHO_CLASS_COL] == 'unknown' ]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = flat_list_tokens(df_test[LITHO_DESC_COL].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' '.join(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(s, title = 'Unclassified via regexp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq(token_freq(flat, n_most_common = 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithologies.append('loam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_litho_markers_re = any_litho_markers_re + '|loam'\n",
    "regex = re.compile(any_litho_markers_re)\n",
    "lithologies_dict['loam'] = 'loam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tokens = v_word_tokenize(t)\n",
    "vt = v_find_litho_markers(v_tokens, regex=regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_litho = [find_primary_lithology(x, lithologies_dict) for x in vt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(set(prim_litho))\n",
    "plot_freq(token_freq(prim_litho, n_most_common = n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blah = pd.DataFrame({ LITHO_CLASS_COL: train_data[LITHO_CLASS_COL], REGEX_LITHO_CLASS_COL: prim_litho, LITHO_DESC_COL: descs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_check_lithoclass(blah, 'loam', colname=REGEX_LITHO_CLASS_COL, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_map['loam'] = 'alluvium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prim_litho=list()\n",
    "for x in prim_litho:\n",
    "    final_prim_litho.append(lithology_map[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq(final_prim_litho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of regex for classifying primary lithologies: \", get_accuracy(final_prim_litho, simplified_lithology))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = pd.DataFrame({ LITHO_CLASS_COL: train_data[LITHO_CLASS_COL], REGEX_LITHO_CLASS_COL: final_prim_litho, LITHO_DESC_COL: descs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = blah.loc[ blah[REGEX_LITHO_CLASS_COL] == 'unknown' ]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = flat_list_tokens(df_test[LITHO_DESC_COL].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' '.join(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(s, title = 'Unclassified via regexp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of regex for classifying primary lithologies: \", get_accuracy(final_prim_litho, simplified_lithology))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the deep learning model on the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data=train_data_unprocessed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/per202/anaconda3/envs/ELA/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# conda install gensim\n",
    "# conda install tensorflow\n",
    "# conda install keras\n",
    "# pip install wordcloud\n",
    "\n",
    "from ela.experiment.textproc import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(train_data,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    RN                  Type   EASTING   NORTHING        Lithology_original  \\\n",
      "0  202  new_bedrock_addition  385411.0  7014147.0                BROWN CLAY   \n",
      "1  202  new_bedrock_addition  385411.0  7014147.0  BROWN CLAY AND PIPE CLAY   \n",
      "2  202  new_bedrock_addition  385411.0  7014147.0           WHITE PIPE CLAY   \n",
      "3  202  new_bedrock_addition  385411.0  7014147.0             RED PIPE CLAY   \n",
      "4  202  new_bedrock_addition  385411.0  7014147.0             CLAY AND SAND   \n",
      "\n",
      "  Simplified_lithology Simplified_lithology_stratigraphy   From     To  \n",
      "0              bedrock                           BEDROCK   0.00  10.67  \n",
      "1              bedrock                           BEDROCK  10.67  24.38  \n",
      "2              bedrock                           BEDROCK  24.38  26.82  \n",
      "3              bedrock                           BEDROCK  26.82  31.70  \n",
      "4              bedrock                           BEDROCK  31.70  50.90  \n",
      "WARNING:tensorflow:From /home/per202/anaconda3/envs/ELA/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/per202/anaconda3/envs/ELA/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 100)           299200    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                1111      \n",
      "=================================================================\n",
      "Total params: 380,711\n",
      "Trainable params: 81,511\n",
      "Non-trainable params: 299,200\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/per202/anaconda3/envs/ELA/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 99809 samples, validate on 33277 samples\n",
      "Epoch 1/10\n",
      " - 125s - loss: 0.4894 - acc: 0.8236 - val_loss: 0.4365 - val_acc: 0.8449\n",
      "Epoch 2/10\n",
      " - 146s - loss: 0.4325 - acc: 0.8462 - val_loss: 0.4294 - val_acc: 0.8498\n",
      "Epoch 3/10\n",
      " - 133s - loss: 0.4229 - acc: 0.8496 - val_loss: 0.4194 - val_acc: 0.8505\n",
      "Epoch 4/10\n",
      " - 131s - loss: 0.4175 - acc: 0.8509 - val_loss: 0.4155 - val_acc: 0.8514\n",
      "Epoch 5/10\n",
      " - 122s - loss: 0.4125 - acc: 0.8539 - val_loss: 0.4144 - val_acc: 0.8530\n",
      "Epoch 6/10\n",
      " - 141s - loss: 0.4102 - acc: 0.8540 - val_loss: 0.4131 - val_acc: 0.8550\n",
      "Epoch 7/10\n",
      " - 150s - loss: 0.4051 - acc: 0.8555 - val_loss: 0.4098 - val_acc: 0.8552\n",
      "Epoch 8/10\n",
      " - 147s - loss: 0.4017 - acc: 0.8574 - val_loss: 0.4129 - val_acc: 0.8515\n",
      "Epoch 9/10\n",
      " - 145s - loss: 0.3986 - acc: 0.8579 - val_loss: 0.4101 - val_acc: 0.8554\n",
      "Epoch 10/10\n",
      " - 161s - loss: 0.3954 - acc: 0.8590 - val_loss: 0.4132 - val_acc: 0.8559\n",
      "Training Accuracy: 0.8601\n",
      "Testing Accuracy:  0.8563\n"
     ]
    }
   ],
   "source": [
    "model.initialise_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning model gives us an accuracy of 87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the accuracy if geolocation and log descriptions are taken as input features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression for classifying lithologies based on geolocation. Combining the outputs of the logistic regression model and the deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_unprocessed.copy()\n",
    "set(train_data['Simplified_lithology'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Simplified_lithology']=train_data['Simplified_lithology'].replace(np.nan,'Unknown',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Simplified_lithology']=train_data['Simplified_lithology'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_data['Simplified_lithology'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Simplified_lithology'],labels=pd.factorize(train_data['Simplified_lithology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_data[['EASTING','NORTHING']][0:len(model.train_X)]\n",
    "test_X=train_data[['EASTING','NORTHING']][len(model.train_X):]\n",
    "train_y=train_data['Simplified_lithology'][0:len(model.train_X)]\n",
    "test_y=train_data['Simplified_lithology'][len(model.train_X):]\n",
    "train_X.replace(np.nan,0.0,inplace=True)\n",
    "test_X.replace(np.nan,0.0,inplace=True)\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(C=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data_unprocessed.copy()\n",
    "new_df=pd.DataFrame(train_data[['Lithology_original']].values,columns=['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[len(model.train_X):].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dl=model.predict_certainity(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_pred_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_pred_dl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_class_prob=np.mean(np.array([y_pred,y_pred_dl]), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_class_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_numerical=np.argmax(final_class_prob,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(test_y,final_output_numerical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_lithology_categories=[]\n",
    "for x in final_output_numerical:\n",
    "    simplified_lithology_categories.append(labels[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not increase the accuracy. Don't think the geolocation has an impact on the simplified lithologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontology based learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python provides libraries such as RDFLib, OWL 2 for working with ontologies. OWL 2 is better suited for ontology oriented programming since it offers a more pythonic way of managing/creating ontologies.\n",
    "But then, RDFLib works well with .rdf files. Hence, there is a trade-off. Can use based on individual project needs. <br>\n",
    "\n",
    "Protege is an 'IDE' which can be used to manage/create ontologies. It was developed at Stanford and can be downloaded from here [Protege](https://protege.stanford.edu/)<br>\n",
    "Protege can be used to visualise the different relationships defined in an ontology <br>\n",
    "\n",
    "The ontology that I am using can be downloaded from [here](http://ontologydesignpatterns.org/wiki/Ontology:CGI_Simple_Lithology_201001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.namespace import SKOS\n",
    "from rdflib.namespace import RDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology=rd.Graph()\n",
    "condamine_litho_ontology = os.path.join(condamine_litho_dir, 'SimpleLithology201001.rdf')\n",
    "ontology.parse(condamine_litho_ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_dictionary=dict()\n",
    "for x,y in ontology.subject_objects(SKOS.prefLabel):\n",
    "    lithology_dictionary[x]=y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in ontology.subject_objects(SKOS.broader):\n",
    "    if x in lithology_dictionary.keys() and y in lithology_dictionary.keys():\n",
    "        print(\" broader class of \",lithology_dictionary[x],\" is \",lithology_dictionary[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>These relationships can be converted into fuzzy if-then rules and fed to the machine learning model to make better decisions. <br>\n",
    "Above is only one kind of relationship. We have other relationships such as narrower, description of each label etc. All these combined would make a very \"knowledgeable\" machine learning model. </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing visually\n",
    "\n",
    "Optional\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations and discussions\n",
    "\n",
    "DL much better than regular expressions.<br>\n",
    "\n",
    "Regular expressions use a set of keywords and look for matches in the descriptions. Sometimes, these keywords might not be in the descriptions.<br>\n",
    "\n",
    "Similarly, regular expressions map descriptions to a set of predefined catgories (clay,sand,etc.) which are further refined into broader categories ( alluvium,basalt,bedrock). Geoscientists confirm that the mapping is not one/many-to-one. For example,Clay could be part of alluvium/basalt. This cannot be achieved using the regular expression model.\n",
    "\n",
    "DL, on the other hand, learns the descriptions of different lithology classes. Based on labelled data from geoscientists, DL model learns the different kinds of descriptions which would pertain to for e.g alluvium. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and future work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ELA)",
   "language": "python",
   "name": "ela"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
